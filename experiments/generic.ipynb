{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- When should wandb.run finished?\n",
    "- When kernel restart, wandb.run not finished, even if I specified it in `__del__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:deepchem.models:Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/ilker/miniconda3/envs/thesis-work/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "INFO:numba.cuda.cudadrv.driver:init\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from thesis_work.utils.data import load_data, load_mixed_interacted_compounds\n",
    "from thesis_work.clustering.runner import ClusterRunner\n",
    "import pandas as pd\n",
    "\n",
    "## To disable all wandb logging\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"./generic.ipynb\"\n",
    "# wandb_project_name = \"clustering-6-targets\"\n",
    "wandb_project_name = \"CPU-vs-GPU-2\"\n",
    "\n",
    "random_state = 42\n",
    "device = \"cuda\"  # TODO: Uncomment for generic experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C(Cc1cccc2ccccc12)Nc1n[nH]c2ccc(N3CCCS3(=O)=...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COC(=O)NC[C@@H](NC(=O)c1ccc(-c2nc(C3CCOCC3)cnc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COc1ccccc1Nc1cc(Oc2cc(C)c(C)nc2-c2ccccn2)ccn1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=C(/C=C/CN1CCCC1)N1CCOc2cc3ncnc(Nc4ccc(F)c(Cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(Nc1cccc(Nc2cc3c(=O)[nH][nH]c(=O)c3cc2Cl)c1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CN(C)CCCCc1cc2c(cc1O)c1c3c(c(-c4ccccc4Cl)cc1n2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>COCCOc1cc2ncc3c(N)nc(-n4ccnc4)cc3c2cc1OC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>COC(=O)c1nc2ccc3ncnc(Nc4ccc(Cl)cc4Cl)c3c2s1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CCC#CC(=O)Nc1cccc(-c2cnc3[nH]ccc3c2)n1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>COc1n[nH]c2cc(NC(=O)N[C@H](C)c3ccc(F)c(Cl)c3)n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  labels\n",
       "0   O=C(Cc1cccc2ccccc12)Nc1n[nH]c2ccc(N3CCCS3(=O)=...       1\n",
       "1   COC(=O)NC[C@@H](NC(=O)c1ccc(-c2nc(C3CCOCC3)cnc...       1\n",
       "2       COc1ccccc1Nc1cc(Oc2cc(C)c(C)nc2-c2ccccn2)ccn1       1\n",
       "3   O=C(/C=C/CN1CCCC1)N1CCOc2cc3ncnc(Nc4ccc(F)c(Cl...       1\n",
       "4   O=C(Nc1cccc(Nc2cc3c(=O)[nH][nH]c(=O)c3cc2Cl)c1...       1\n",
       "..                                                ...     ...\n",
       "95  CN(C)CCCCc1cc2c(cc1O)c1c3c(c(-c4ccccc4Cl)cc1n2...       1\n",
       "96           COCCOc1cc2ncc3c(N)nc(-n4ccnc4)cc3c2cc1OC       1\n",
       "97        COC(=O)c1nc2ccc3ncnc(Nc4ccc(Cl)cc4Cl)c3c2s1       1\n",
       "98             CCC#CC(=O)Nc1cccc(-c2cnc3[nH]ccc3c2)n1       1\n",
       "99  COc1n[nH]c2cc(NC(=O)N[C@H](C)c3ccc(F)c(Cl)c3)n...       1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_type = \"kinase\"\n",
    "# protein_type = \"protease\"\n",
    "# protein_type = \"gpcr\"\n",
    "\n",
    "protein_types = [protein_type]\n",
    "\n",
    "smiles_df = load_data(protein_type=protein_type)\n",
    "\n",
    "smiles_df = smiles_df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours - Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_sample_size = 1000\n",
    "protein_types = [\n",
    "    \"gpcr\",\n",
    "    \"ionchannel\",\n",
    "    \"kinase\",\n",
    "    \"nuclearreceptor\",\n",
    "    \"protease\",\n",
    "    \"transporter\",\n",
    "]\n",
    "protein_types.sort()\n",
    "protein_labels = list(range(len(protein_types)))\n",
    "\n",
    "smiles_df = load_mixed_interacted_compounds(\n",
    "    protein_types=protein_types,\n",
    "    each_sample_size=each_sample_size,\n",
    "    random_state=random_state,\n",
    "    convert_labels=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Drop invalid SMILES\n",
    "\n",
    "from thesis_work.utils.utils import get_largest_fragment_from_smiles\n",
    "\n",
    "protein_types = [\"BBBP\"]\n",
    "\n",
    "# Read in data from MoleculeNet\n",
    "smiles_df = pd.read_csv(\n",
    "    \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/BBBP.csv\"\n",
    ")\n",
    "\n",
    "# Clean up columnn names so they are easier to interpret\n",
    "smiles_df = (\n",
    "    smiles_df[[\"smiles\", \"p_np\", \"name\"]]\n",
    "    .reset_index(drop=True)\n",
    "    .rename({\"smiles\": \"text\", \"p_np\": \"labels\"}, axis=1)\n",
    ")\n",
    "\n",
    "# Remove extra fragments in SMILES (typically salts, which are irrelevant to BBB permeability)\n",
    "smiles_df[\"text\"] = (\n",
    "    smiles_df[\"text\"].apply(get_largest_fragment_from_smiles).dropna().astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUNNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "num_threads = None\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "model_name = \"DeepChem/ChemBERTa-77M-MTR\"\n",
    "# model_name = \"DeepChem/ChemBERTa-77M-MLM\"\n",
    "# model_name = \"ecfp\"\n",
    "# model_name = \"chemprop\"\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "n_components = 25\n",
    "\n",
    "# dimensionality_reduction_method = None\n",
    "# dimensionality_reduction_method_kwargs = None\n",
    "\n",
    "dimensionality_reduction_method = \"UMAP\"\n",
    "dimensionality_reduction_method_kwargs = {\n",
    "    \"n_components\": n_components,\n",
    "    \"n_neighbors\": 15,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"metric\": \"euclidean\",\n",
    "}\n",
    "\n",
    "# dimensionality_reduction_method = \"PCA\"\n",
    "# dimensionality_reduction_method_kwargs = {\n",
    "#     \"n_components\": n_components,\n",
    "# }\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "clustering_method = \"K-MEANS\"\n",
    "clustering_method_kwargs = {\n",
    "    \"init_method\": \"k-means++\",\n",
    "    \"n_clusters\": 6,\n",
    "    \"n_init\": 1,\n",
    "}\n",
    "\n",
    "# clustering_method = \"BUTINA\"\n",
    "# clustering_method_kwargs = {\n",
    "#     # \"distance_metric\": \"tanimoto\",\n",
    "#     \"distance_metric\": \"euclidean\",\n",
    "#     \"threshold\": 0.35,\n",
    "# }\n",
    "\n",
    "# clustering_method = \"DBSCAN\"\n",
    "# clustering_method_kwargs = {\n",
    "#     \"min_samples\": 5,\n",
    "#     \"metric\": \"euclidean\",\n",
    "# }\n",
    "\n",
    "# clustering_method = \"HDBSCAN\"\n",
    "# clustering_method_kwargs = {\n",
    "#     \"min_cluster_size\": 5,\n",
    "#     \"metric\": \"euclidean\",\n",
    "# }\n",
    "\n",
    "##################################################################################\n",
    "\n",
    "wandb_extra_configs = None\n",
    "# wandb_extra_configs = {\"proteins\": protein_types} # TODO: Uncomment for generic experiments\n",
    "\n",
    "\n",
    "# wandb_run_name = None\n",
    "wandb_run_name = f\"\"\"\n",
    "    {clustering_method}_\n",
    "    {model_name if \"/\" not in model_name else model_name.split(\"/\")[1]}\n",
    "\"\"\"\n",
    "\n",
    "if dimensionality_reduction_method is not None:\n",
    "    wandb_run_name += f\"_{dimensionality_reduction_method}\"\n",
    "\n",
    "if dimensionality_reduction_method_kwargs is not None:\n",
    "    wandb_run_name += f\"_{dimensionality_reduction_method_kwargs['n_components']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_runner = ClusterRunner(\n",
    "    wandb_project_name=wandb_project_name,\n",
    "    wandb_run_name=wandb_run_name,\n",
    "    wandb_extra_configs=wandb_extra_configs,\n",
    "    smiles_df=smiles_df,\n",
    "    # smiles_df_path = None,\n",
    "    model_name=model_name,\n",
    "    random_state=random_state,\n",
    "    device=device,\n",
    "    dimensionality_reduction_method=dimensionality_reduction_method,\n",
    "    dimensionality_reduction_method_kwargs=dimensionality_reduction_method_kwargs,\n",
    "    clustering_method=clustering_method,\n",
    "    clustering_method_kwargs=clustering_method_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data must be a string or an io object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# min_cluster_sizes = None\u001b[39;00m\n\u001b[1;32m     11\u001b[0m min_cluster_sizes \u001b[39m=\u001b[39m [\u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m25\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m cluster_runner\u001b[39m.\u001b[39;49mrun_clustering()\n\u001b[1;32m     14\u001b[0m \u001b[39m# cluster_runner.run_multiple_clustering(\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#     n_clusters=n_clusters, thresholds=thresholds, min_cluster_sizes=min_cluster_sizes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mdel\u001b[39;00m cluster_runner\n",
      "File \u001b[0;32m~/Documents/MyRepos/thesis-work/thesis_work/clustering/runner.py:409\u001b[0m, in \u001b[0;36mClusterRunner.run_clustering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_clustering()\n\u001b[1;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_clustering()\n",
      "File \u001b[0;32m~/Documents/MyRepos/thesis-work/thesis_work/clustering/runner.py:375\u001b[0m, in \u001b[0;36mClusterRunner._run_clustering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_dimensionality_reduction()\n\u001b[1;32m    373\u001b[0m \u001b[39m# FIXME: If labels not present, this won't work\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m# FIXME: legend_title should be different for active-inactive datasets\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_umap_2D(\n\u001b[1;32m    376\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvector_embeddings,\n\u001b[1;32m    377\u001b[0m     labels\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msmiles_df[\u001b[39m\"\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    378\u001b[0m     log_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mOriginal Labels\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    379\u001b[0m     legend_title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mProtein Family\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    382\u001b[0m clustering_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclustering_method_kwargs\n\u001b[1;32m    383\u001b[0m clustering_kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvector_embeddings\n",
      "File \u001b[0;32m~/Documents/MyRepos/thesis-work/thesis_work/clustering/runner.py:312\u001b[0m, in \u001b[0;36mClusterRunner.log_umap_2D\u001b[0;34m(self, data, labels, log_name, legend_title)\u001b[0m\n\u001b[1;32m    301\u001b[0m umap_2d_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m    302\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: labels, \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m: umap_output[:, \u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m: umap_output[:, \u001b[39m1\u001b[39m]},\n\u001b[1;32m    303\u001b[0m     index\u001b[39m=\u001b[39mlabels,\n\u001b[1;32m    304\u001b[0m )\n\u001b[1;32m    306\u001b[0m umap_2d_figure \u001b[39m=\u001b[39m plot_umap(\n\u001b[1;32m    307\u001b[0m     data\u001b[39m=\u001b[39mumap_2d_data,\n\u001b[1;32m    308\u001b[0m     plot_title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m     legend_title\u001b[39m=\u001b[39mlegend_title,\n\u001b[1;32m    310\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mplotly\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    311\u001b[0m )\n\u001b[0;32m--> 312\u001b[0m log_plotly_figure(figure\u001b[39m=\u001b[39;49mumap_2d_figure, name\u001b[39m=\u001b[39;49mlog_name)\n",
      "File \u001b[0;32m~/Documents/MyRepos/thesis-work/thesis_work/utils.py:74\u001b[0m, in \u001b[0;36mlog_plotly_figure\u001b[0;34m(figure, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m path_to_plotly_html \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m./plotly_figure.html\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m figure\u001b[39m.\u001b[39mwrite_html(path_to_plotly_html, auto_play\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m table\u001b[39m.\u001b[39madd_data(wandb\u001b[39m.\u001b[39;49mHtml(path_to_plotly_html))\n\u001b[1;32m     75\u001b[0m wandb\u001b[39m.\u001b[39mlog({name: table})\n\u001b[1;32m     77\u001b[0m \u001b[39m# Remove the file\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis-work/lib/python3.10/site-packages/wandb/sdk/data_types/html.py:46\u001b[0m, in \u001b[0;36mHtml.__init__\u001b[0;34m(self, data, inject)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhtml \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mread()\n\u001b[1;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdata must be a string or an io object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m inject:\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minject_head()\n",
      "\u001b[0;31mValueError\u001b[0m: data must be a string or an io object"
     ]
    }
   ],
   "source": [
    "# n_clusters = None\n",
    "n_clusters = list(range(2, 100))\n",
    "\n",
    "# thresholds = None\n",
    "thresholds = [0.2, 0.35, 0.5, 0.8]\n",
    "\n",
    "# min_samples = None\n",
    "min_samples = [10, 20]\n",
    "\n",
    "# min_cluster_sizes = None\n",
    "min_cluster_sizes = [5, 10, 15, 20, 25]\n",
    "\n",
    "cluster_runner.run_clustering()\n",
    "# cluster_runner.run_multiple_clustering(\n",
    "#     n_clusters=n_clusters, thresholds=thresholds, min_cluster_sizes=min_cluster_sizes\n",
    "# )\n",
    "\n",
    "del cluster_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cluster_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No runs to be synced.\n"
     ]
    }
   ],
   "source": [
    "!wandb sync --clean-old-hours 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU VS GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For forcing to use CPU even if GPU is available\n",
    "\n",
    "# import os\n",
    "# from cuml.common.device_selection import using_device_type\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# with using_device_type('cpu'):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import time\n",
    "\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\"\n",
    "os.environ[\"WANDB_RUN_ID\"] = wandb.util.generate_id()\n",
    "\n",
    "num_threads = None\n",
    "# num_threads = 1\n",
    "\n",
    "# wandb_run_name = None\n",
    "wandb_run_name = \"GPU\"\n",
    "\n",
    "device = \"cuda\"\n",
    "# device = \"cpu\"\n",
    "\n",
    "# mol_nums = [100, 200, 500, 1_000, 5_000, 10_000]\n",
    "mol_nums = [100, 200, 500, 1_000, 5_000, 10_000, 20_000]\n",
    "\n",
    "for mol_num in mol_nums:\n",
    "    protein_type = \"kinase\"\n",
    "    protein_types = [protein_type]\n",
    "    wandb_extra_configs = {\"proteins\": protein_types}\n",
    "\n",
    "    smiles_df = load_data(protein_type=protein_type)\n",
    "    smiles_df = smiles_df[:mol_num]\n",
    "\n",
    "    cluster_runner = ClusterRunner(\n",
    "        wandb_project_name=wandb_project_name,\n",
    "        wandb_run_name=wandb_run_name,\n",
    "        wandb_extra_configs=wandb_extra_configs,\n",
    "        smiles_df=smiles_df,\n",
    "        # smiles_df_path = None,\n",
    "        model_name=model_name,\n",
    "        random_state=random_state,\n",
    "        device=device,\n",
    "        dimensionality_reduction_method=dimensionality_reduction_method,\n",
    "        dimensionality_reduction_method_kwargs=dimensionality_reduction_method_kwargs,\n",
    "        clustering_method=clustering_method,\n",
    "        clustering_method_kwargs=clustering_method_kwargs,\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    cluster_runner.run_clustering()\n",
    "    end_time = time.time()\n",
    "    wandb.log({\"running_time\": end_time - start_time, \"molecule_number\": mol_num})\n",
    "    del cluster_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
